webpackJsonp([22],{nAA5:function(a,e,t){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"content"},[t("hr"),a._v(" "),t("h2",{attrs:{id:"name%3A-linux%E7%BD%91%E7%BB%9Cio%E5%B9%B6%E8%A1%8C%E5%8C%96%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88layout%3A-posttitle%3A-%22linux%E7%BD%91%E7%BB%9Cio%E5%B9%B6%E8%A1%8C%E5%8C%96%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88%22info%3A-%22linux%E7%BD%91%E7%BB%9Cio%E5%B9%B6%E8%A1%8C%E5%8C%96%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88%22date%3A-2019-05-05categories%3A-worktags%3A-%5Blinux%5Dcoverimg%3A-%22https%3A%2F%2Fws1.sinaimg.cn%2Flarge%2F88b26e1cgy1fx7cwh57tlj22kw3vc1ky.jpg%22"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#name%3A-linux%E7%BD%91%E7%BB%9Cio%E5%B9%B6%E8%A1%8C%E5%8C%96%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88layout%3A-posttitle%3A-%22linux%E7%BD%91%E7%BB%9Cio%E5%B9%B6%E8%A1%8C%E5%8C%96%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88%22info%3A-%22linux%E7%BD%91%E7%BB%9Cio%E5%B9%B6%E8%A1%8C%E5%8C%96%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88%22date%3A-2019-05-05categories%3A-worktags%3A-%5Blinux%5Dcoverimg%3A-%22https%3A%2F%2Fws1.sinaimg.cn%2Flarge%2F88b26e1cgy1fx7cwh57tlj22kw3vc1ky.jpg%22","aria-hidden":"true"}},[a._v("#")]),a._v(' name: Linux网络IO并行化技术概览\nlayout: post\ntitle:  "Linux网络IO并行化技术概览"\ninfo: "Linux网络IO并行化技术概览"\ndate:   2019-05-05\ncategories: WORK\ntags: [Linux]\ncoverimg: "https://ws1.sinaimg.cn/large/88b26e1cgy1fx7cwh57tlj22kw3vc1ky.jpg"')]),a._v(" "),t("h3",{attrs:{id:"%E5%89%8D%E8%A8%80"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#%E5%89%8D%E8%A8%80","aria-hidden":"true"}},[a._v("#")]),a._v(" 前言")]),a._v(" "),t("ul",[t("li",[a._v("我们或许经常听到关于什么是最好的服务器编程语言、怎样是最好的架构设计的讨论，却从未听到有人讨论什么是最好的服务器操作系统，实际上它的地位早已重要到我们习惯地把它作为一个标准而非一个选择")]),a._v(" "),t("li",[a._v("如今Linux在性能、稳定、易用等方面持续不断的提升。作为用户很多时候我们发现问题已不在于Linux能否跟上我们的需求，而在于我们能否及时了解掌握Linux的众多功能特性而加以利用")]),a._v(" "),t("li",[a._v("网络协议栈处理，本质来说是CPU密集的计算，所以多年来各种关键优化补丁的共同思路，基本都是怎么充分利用多核的资源达到计算并行")]),a._v(" "),t("li",[a._v("协议栈计算本身是一个复杂的分层的处理过程，在各个层各处理环节都有并行优化的空间")])]),a._v(" "),t("h3",{attrs:{id:"linux%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E6%B5%81%E7%A8%8B"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#linux%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E6%B5%81%E7%A8%8B","aria-hidden":"true"}},[a._v("#")]),a._v(" Linux网络数据传输流程")]),a._v(" "),t("ul",[t("li",[a._v("网卡硬件(NIC)接受到数据包后将数据写入两个内存唤醒队列并触发中断")]),a._v(" "),t("li",[a._v("CPU收到中断后OS将陷入中断处理程序中执行，这个过程叫做硬中断")]),a._v(" "),t("li",[a._v("为了减少中断处理程序执行时间，内核将硬中断处理中无需实时同步完成的工作delay到一个准实时的异步程序中执行，该异步机制被称为软中断")]),a._v(" "),t("li",[a._v("软中断处理完成的数据提交给IP层进行处理")]),a._v(" "),t("li",[a._v("IP层处理完分片和路由后将提交给传输层处理")]),a._v(" "),t("li",[a._v("传输层将处理好的数据放到对应的socket对象接受队列中，并唤醒阻塞在socket上的进程")]),a._v(" "),t("li",[a._v("用户态进程通过socket fd来操作内核中的socket对象")])]),a._v(" "),t("h3",{attrs:{id:"%E4%B8%AD%E6%96%AD%E8%B0%83%E5%BA%A6"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#%E4%B8%AD%E6%96%AD%E8%B0%83%E5%BA%A6","aria-hidden":"true"}},[a._v("#")]),a._v(" 中断调度")]),a._v(" "),t("h4",{attrs:{id:"%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86","aria-hidden":"true"}},[a._v("#")]),a._v(" 中断处理")]),a._v(" "),t("ul",[t("li",[a._v("协议栈对入包的软件部分处理，总是从硬中断(Hard-IRQ)处理开始的")]),a._v(" "),t("li",[a._v("计算机系统中有很多不同作用的中断请求，由中断号唯一标识，比如每块网卡有自己的中断号")]),a._v(" "),t("li",[a._v("对每个中断号，系统都会注册一个handler(也就我们通常说的中断处理程序)")]),a._v(" "),t("li",[a._v("在Hard-IRQ handler中(如网卡中断处理程序)通常将无需立即完成的工作(如TCP/IP协议栈处理)通过Soft-IRQ异步地执行")]),a._v(" "),t("li",[a._v("Soft-IRQ顾名思义就是软件构造的类似的中断机制，它也根据用途区分不同的类型，并有对应的handler。它存在的主要意义是让中断对系统实时性的影响尽可能小")])]),a._v(" "),t("h4",{attrs:{id:"%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6","aria-hidden":"true"}},[a._v("#")]),a._v(" 调度机制")]),a._v(" "),t("ul",[t("li",[a._v("不管是Hard-IRQ还是Soft-IRQ handler，它们都是一段需要调度的执行流(就像线程一样)")]),a._v(" "),t("li",[a._v("对同一个中断号的Hard-IRQ handler，在全局上是串行执行的，即同时只能在一个核上执行")]),a._v(" "),t("li",[a._v("对不同的中断号的Hard-IRQ handler，可以在不同的核上并行执行")]),a._v(" "),t("li",[a._v("某个中断号在哪个核上执行，通常由系统中的I/O APIC(高级可编程中断控制器)来决定，内核提供了配置接口（也有一种称为irqbalance的动态调整工具可选）")]),a._v(" "),t("li",[a._v("Hard-IRQ handler中发起的Soft-IRQ，一般在同一个core上执行")]),a._v(" "),t("li",[a._v("传统的网卡每块设备有一个中断号，协议栈处理的并行化是以网卡设备为粒度的")]),a._v(" "),t("li",[a._v("如果只有单块网卡，就会发现中断处理CPU消耗集中在一个核心上")]),a._v(" "),t("li",[a._v("如果有多块网卡，通常会因为多核并行而获得性能提升，但如果两个不同核心是使用超线程技术对同一物理核心虚拟出的两个逻辑核心则不能有效的并行处理，解决方式是手动配置中断亲和")])]),a._v(" "),t("h4",{attrs:{id:"%E5%A4%9A%E9%98%9F%E5%88%97%E7%BD%91%E5%8D%A1"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#%E5%A4%9A%E9%98%9F%E5%88%97%E7%BD%91%E5%8D%A1","aria-hidden":"true"}},[a._v("#")]),a._v(" 多队列网卡")]),a._v(" "),t("ul",[t("li",[a._v("从硬中断的层面支持单网卡IO的并行")]),a._v(" "),t("li",[a._v("多队列网卡通过引入RX-Queue的机制，将输入流量水平分到多个虚拟的网卡也就是RX-Queue")]),a._v(" "),t("li",[a._v("每个RX-Queue像一个独立设备一样有自己的中断号，并可以独立并行工作")]),a._v(" "),t("li",[a._v("RX—Queue的数量一般可以配置为和核心数一致，可充分利用多核资源")]),a._v(" "),t("li",[a._v("输入流量拆分到RX-Queue的算法是Hash，如出现大部分流量来自少量IP：PORT则效果不好")])]),a._v(" "),t("h4",{attrs:{id:"rps"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rps","aria-hidden":"true"}},[a._v("#")]),a._v(" RPS")]),a._v(" "),t("ul",[t("li",[a._v("RPS是工作在NAPI层(或者说在Soft-IRQ处理中接近入口的位置)的入流量分发机制，它利用了前面提到的Per-CPU的backlog队列来将数据包分发到目标core上")]),a._v(" "),t("li",[a._v("默认的分发算法与多队列机制类似，也是使用IP,Port四元组的哈希来映射到某一个core")]),a._v(" "),t("li",[a._v("一般情况下有队列网卡的环境下配置RPS不会再有明显的提升")])]),a._v(" "),t("h4",{attrs:{id:"rfs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rfs","aria-hidden":"true"}},[a._v("#")]),a._v(" RFS")]),a._v(" "),t("ul",[t("li",[a._v("RFS是在RPS分发机制基础上的一个扩展")]),a._v(" "),t("li",[a._v("首先RFS会维护一张全局的路由表（图中SockFlowTable），表中记录了一个FlowHash(四元组的Hash值)到对应CPU核的路由项")]),a._v(" "),t("li",[a._v("在RPS做包转发时，实际它会先判断是否启用了RFS，并且能找到有效的RFS路由项，否则的话仍使用默认RPS逻缉进行转发")])]),a._v(" "),t("h4",{attrs:{id:"xps"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#xps","aria-hidden":"true"}},[a._v("#")]),a._v(" XPS")]),a._v(" "),t("ul",[t("li",[a._v("XPS解决的是一个在多队列网卡场景下才存在的问题：默认情况下当协议栈处理到需要向一个网卡设备发包时，如果是多队列网卡(有多个TX-Queue)，会使用四元组hash的方式选择一个TX-Queue进行发送")]),a._v(" "),t("li",[a._v("这里有一个性能损耗是，在多核的场景下，可能会存多个核同时向一个TX-Queue发送数据的情况，因为这个操作需要写相应的tx_ring等内存，会引发cache line bouncing的问题，带来系统整体性能的下降")]),a._v(" "),t("li",[a._v("而XPS提供这样一种机制，可以将不同的TX-Queue固定地分配给不同的CPU集合去操作，这样对于某一个TX-Queue，仅有一个或少数几个CPU核会去写，可以避免或大大减少冲突写带来的cache line bouncing问题")])]),a._v(" "),t("h4",{attrs:{id:"so_reuseport"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#so_reuseport","aria-hidden":"true"}},[a._v("#")]),a._v(" SO_REUSEPORT")]),a._v(" "),t("ul",[t("li",[a._v("SO_REUSEPORT很好地解决了多进程读写同一端口场景的2个问题：负载均衡和访问竞争")]),a._v(" "),t("li",[a._v("通过这个选项，多个用户进程/线程可以各自创建一个独立socket，但它们又共享同一端口，该端口的流量默认按四元组hash的方式分发各socket上（最新内核还支持使用bpf方式自定义分发策略），思路是不是非常熟悉")])])])}]},r=t("VU/8")(null,i,!1,null,null,null);e.default=r.exports}});
//# sourceMappingURL=22.cd7dd2c9f2642994e69a.js.map